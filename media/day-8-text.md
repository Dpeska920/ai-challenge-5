## Отчет: Влияние токенов и контекста на работу нейросети

### Настройка max_tokens 
Этот параметр задает лимит исключительно на размер генерируемого ответа.

Если ответ укладывается в этот объем, мы видим его целиком.

Если ответ превышает лимит, он механически обрезается.

Важно: Тестирование показало, что max_tokens не влияет на входящие данные и практически не сказывается на «интеллекте» или качестве самого ответа.

### Ограничение размера контекста (Context Window) 
Этот параметр определяет объем «памяти» нейросети - сумму токенов запроса и ответа, которую модель может удержать во внимании. Последствия превышения этого лимита зависят от способа использования нейросети.

При прямом или локальном использовании наблюдаются некоторые проблемы. Если запрос или генерация выходят за пределы контекстного окна, поведение модели становится непредсказуемым. Она может потерять нить рассуждения, начать галлюцинировать, зацикливаться (повторять одно и то же) или генерировать бессвязный бред.

При использовании через API и облачные сервисы, провайдеры обычно ставят жесткие программные барьеры. Сервис не доводит модель до состояния «бреда», а заранее возвращает ошибку (например, Context limit exceeded) или принудительно обрезает историю диалога/ответ.

Вывод: При работе с нейросетями необходимо строго следить за размером контекста. Для локальных решений это критично для сохранения адекватности модели (защита от галлюцинаций), а для API — для предотвращения технических ошибок и отказов в обслуживании.